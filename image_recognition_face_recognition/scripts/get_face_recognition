#!/usr/bin/env python
from __future__ import print_function
from image_recognition_msgs.msg import Recognition
from image_recognition_face_recognition.facenet_recognition import FacenetRecognition
from sensor_msgs.msg import RegionOfInterest
from image_recognition_util import image_writer
import argparse
import math
import cv2

parser = argparse.ArgumentParser(description='Get face recognitions')

# Add arguments
parser.add_argument('image', type=str, help='Image')
parser.add_argument(
    '-v', '--verbose', help="Increase output verbosity", action="store_true")
args = parser.parse_args()

# Read the image
img = cv2.imread(args.image)

# Create openface interface
face_recognizer = FacenetRecognition()

recognized_faces = face_recognizer.face_detection(img)
print(recognized_faces)

recognitions = []
for fr in recognized_faces:
    face_recognition = [math.floor(xi) for xi in fr]
    recognitions.append(Recognition(
        roi=RegionOfInterest(
            x_offset=face_recognition[0],
            y_offset=face_recognition[1],
            width=face_recognition[2] - face_recognition[0],
            height=face_recognition[3] - face_recognition[1],
        )
    )
)
    annotated_original_image = image_writer.get_annotated_cv_image(img, recognitions) 
cv2.imshow("result", annotated_original_image)
cv2.waitKey(1000)